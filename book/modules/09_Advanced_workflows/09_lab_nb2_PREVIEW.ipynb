{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f1cb9bd-7fdb-4d5e-97bd-024c306527e8",
   "metadata": {},
   "source": [
    "# Lab 09 assignment (20 pts)\n",
    "*Notebook 2 of 2*\n",
    "\n",
    "UW Geospatial Data Analysis  \n",
    "CEE467/CEWA567  \n",
    "David Shean, Eric Gagliano, Quinn Brencher"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0871eb-e6b5-496d-a7fb-49d49d513de5",
   "metadata": {},
   "source": [
    "## Setup from Notebook 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "825ea488-d085-4166-a199-863967f03128",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pystac_client\n",
    "import planetary_computer\n",
    "import xarray as xr\n",
    "import rasterio as rio\n",
    "import rioxarray\n",
    "import geopandas as gpd\n",
    "import odc.stac\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "import os\n",
    "import rasterstats\n",
    "from rioxarray import merge\n",
    "import scipy.ndimage as ndimage\n",
    "from skimage.segmentation import watershed\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage.measure import label\n",
    "from shapely.geometry import shape\n",
    "from rasterio.features import shapes, rasterize\n",
    "import xyzservices.providers as xyz\n",
    "import argparse\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c261d639-ea20-4b10-8e3a-0365c9a14432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bounding box for area of interest in lat lon\n",
    "minx = 141.9\n",
    "maxx = 142.0\n",
    "miny = 42.7\n",
    "maxy = 42.75\n",
    "bbox = (minx, miny, maxx, maxy)\n",
    "\n",
    "# date in utc time\n",
    "earthquake_date = \"2018-09-05\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11eea30-eca5-425d-b0a7-f3c596252a6b",
   "metadata": {},
   "source": [
    "Functions defined in Notebook 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b5b2199-aadf-46f3-84cb-321f8076600a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_date_before(date_str, days_padding=1):\n",
    "    date = pd.Timestamp(date_str)  # Convert string to pandas Timestamp\n",
    "    date_before = date - pd.DateOffset(days=days_padding)\n",
    "    return date_before.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "def calculate_date_range(date_str, months_padding=3):\n",
    "    date = pd.Timestamp(date_str)  # Convert string to pandas Timestamp\n",
    "    start_date = date - pd.DateOffset(months=months_padding)\n",
    "    end_date = date + pd.DateOffset(months=months_padding)\n",
    "    return start_date.strftime(\"%Y-%m-%d\"), end_date.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "def step_function(t, a, b, t0, k=10):\n",
    "    return a + b / (1 + np.exp(-k * (t - t0))) \n",
    "\n",
    "def fit_step_function(observed_values, time_values, date_of_interest):\n",
    "    \"\"\"Fit step function to a single pixel time series.\"\"\"\n",
    "    # mask nodata values \n",
    "    mask = ~np.isnan(observed_values)\n",
    "    \n",
    "    if np.sum(mask) < 5:  # skip if not enough valid points\n",
    "        return np.nan, np.nan, np.nan\n",
    "    \n",
    "    try:\n",
    "        # convert valid values\n",
    "        t_valid = time_values[mask].astype(float)\n",
    "        observed_valid = observed_values[mask]\n",
    "\n",
    "        # initial guesses: baseline observed value, rough estimate observed value change, and date of interest\n",
    "        p0 = [0, -0.2, np.datetime64(date_of_interest).astype(\"datetime64[ns]\").astype(float)]\n",
    "        \n",
    "        # fit the step function\n",
    "        params, _ = curve_fit(step_function, t_valid, observed_valid, p0=p0)\n",
    "\n",
    "        return params[0], params[1], params[2]  # a (baseline), b (step size), t0 (change date)\n",
    "\n",
    "    except RuntimeError:\n",
    "        return np.nan, np.nan, np.nan  # return NaN if fitting fails"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503fbdec-5c67-4126-ab3e-34c1bc02fcdb",
   "metadata": {},
   "source": [
    "## Part 4: Writing functions (6 pts)\n",
    "Now we're going to apply some of the best practices described in the demo to turn our landslide inventory workflow into a series of robust, well-documented functions that are ready to go into a module. Note that all of the code necessary to complete these functions should be already finished in the previous notebook (no need to do additional analysis here). We'll provide some flexibility in terms of how you translate this code into functions, but please use best practices. In this section, each function that you create should have:\n",
    "1) Good naming conventions\n",
    "2) Helpful comments\n",
    "3) A docstring (including a high-level overview and description of inputs and outputs)\n",
    "4) Type hints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4917d5e4-d8ea-4915-8393-6102c8ed17a0",
   "metadata": {},
   "source": [
    "### 4.1 Data download and preprocessing\n",
    "#### *Write a function (or a small group of functions) that prepares the seasonal NDVI time series.*\n",
    "Your function (or group of functions, collectively) should have the following arguments:\n",
    "- an earthquake date\n",
    "- a bounding box\n",
    "- allowed cloud cover percent in Sentinel-2 images (with default value 80)\n",
    "\n",
    "And return the following outputs:\n",
    "- an Xarray Dataset with dimensions `x`, `y`, and `season` and data variable `NDVI`.\n",
    "\n",
    "Run your function(s) and save the output to a variable to make sure it works.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d85f5c6-8ebd-471d-89da-81836b00e481",
   "metadata": {
    "tags": [
     "hide_content"
    ]
   },
   "outputs": [],
   "source": [
    "# STUDENT CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aecbc222-1ea7-435c-90e8-5cb066356c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/rasterio/warp.py:387: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix will be returned.\n",
      "  dest = _reproject(\n"
     ]
    }
   ],
   "source": [
    "seasonal_ds = get_seasonal_ndvi(earthquake_date, bbox)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09497be-b336-471b-8f1b-1c5ff2f77856",
   "metadata": {},
   "source": [
    "#### *Write a function (or a small group of functions) that prepares the NDVI time series spanning the earthquake date.*\n",
    "Your function (or group of functions, collectively) should have the following arguments:\n",
    "- an earthquake date\n",
    "- a bounding box,\n",
    "- the seasonal NDVI time series Dataset (output by the function(s) above)\n",
    "- allowed cloud cover percent in Sentinel-2 images (with default set to 50)\n",
    "\n",
    "And return the following outputs:\n",
    "- an Xarray Dataset with dimensions `x`, `y`, and `time`, and data variables `NDVI` and `NDVI_anomaly`\n",
    "\n",
    "Run your function(s) and save the output to a variable to make sure it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b4b3b3f-34f4-46a8-a4bb-2f428ad403e5",
   "metadata": {
    "tags": [
     "hide_content"
    ]
   },
   "outputs": [],
   "source": [
    "# STUDENT CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ee7ff77-057d-4f61-aeb1-c27341820119",
   "metadata": {},
   "outputs": [],
   "source": [
    "s2_ds = get_ndvi_timeseries(earthquake_date, bbox, seasonal_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3c0114-e2a4-4bfd-a080-509c4b0fe21f",
   "metadata": {},
   "source": [
    "### 4.2 Fitting a step function and creating a landslide mask\n",
    "#### *Write a function (or a small group of functions) that fits a step function to the `NDVI_anomaly` time series and creates a landslide mask.*\n",
    "Your function (or group of functions, collectively) should have the following arguments:\n",
    "- an earthquake date\n",
    "- a Sentinel-2 time series Xarray dataset with data variable `NDVI_anomaly`\n",
    "\n",
    "And return the following outputs:\n",
    "-   the input Xarray dataset, now with additional data variable `landslide_mask`. \n",
    "\n",
    "Run your function(s) and save the output to a variable to make sure it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "522cd175-c0a8-41ba-ab3a-fc0831c7ed51",
   "metadata": {
    "tags": [
     "hide_content"
    ]
   },
   "outputs": [],
   "source": [
    "# STUDENT CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a90fef06-8309-43b2-aec4-b0b737765489",
   "metadata": {},
   "outputs": [],
   "source": [
    "s2_ds = create_landslide_mask(earthquake_date, s2_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfcf264-80e6-4f96-9b2d-4bd8481ff3ce",
   "metadata": {},
   "source": [
    "### 4.3 Landslide segmentation\n",
    "#### *Write a function (or a small group of functions) that cleans up the landslide mask using binary erosion and dilation, then segments the landslide mask to label each individual landslide.*\n",
    "Your function (or group of functions, collectively) should have the following arguments:\n",
    "- a Sentinel-2 time series Xarray dataset with data variable `landslide_mask`\n",
    "\n",
    "And return the following outputs:\n",
    "-   the input Xarray dataset, now with additional variable `landslide_id`\n",
    "\n",
    "Run your function(s) and save the output to a variable to make sure it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b80d3f9-7033-4ce1-9376-c6b21e5834dd",
   "metadata": {
    "tags": [
     "hide_content"
    ]
   },
   "outputs": [],
   "source": [
    "# STUDENT CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0cdfcad-ff71-415e-a779-d5ac57c5909b",
   "metadata": {},
   "outputs": [],
   "source": [
    "s2_ds = segment_landslides(s2_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738214f0-d1c3-4445-a2e9-e90d4ce09e2a",
   "metadata": {},
   "source": [
    "### 4.4 Polygonize landslides \n",
    "#### *Finally, write a function (or a small group of functions) that turns our landslides_id raster into a vector dataset.*\n",
    "Your function (or group of functions, collectively) should have the following arguments:\n",
    "- an earthquake date\n",
    "- a bbox\n",
    "- a Sentinel-2 time series Xarray dataset with data variable `landslide_id`\n",
    "\n",
    "Your function should `return None`, but it should write a GeoDataFrame with entries for each landslide to disk as a `.geojson` file. \n",
    "\n",
    "Run your function(s) and check to see what was written to the disk to make sure it works. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a290d4b5-d71a-4922-b564-bf8c78fb89b3",
   "metadata": {
    "tags": [
     "hide_content"
    ]
   },
   "outputs": [],
   "source": [
    "# STUDENT CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c54dd27b-b9dc-41a7-9ad1-2e3587b608d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "polygonize_landslides(earthquake_date, bbox, s2_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c103e573-248f-4c8f-bab7-5bc9c974d7b7",
   "metadata": {},
   "source": [
    "#### *Challenge question (GS required/UG +0.5):*\n",
    "- Raise an exception in a scenario where one of these functions might silently fail (hint: maybe where no Sentinel-2 data are available? Maybe when no landslides are found?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5720ce32-a3a0-4cc8-9ee9-2a0c874d9c41",
   "metadata": {
    "tags": [
     "hide_content"
    ]
   },
   "outputs": [],
   "source": [
    "# STUDENT CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8dc7f69-9182-47db-bacc-4f75a6bf65a5",
   "metadata": {},
   "source": [
    "#### *Challenge Question (GS required/UG +0.5): Write a test for one of these functions.*\n",
    "Run your test to see if it's working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba8092d6-c12f-40a7-a274-ed09d1802fca",
   "metadata": {
    "tags": [
     "hide_content"
    ]
   },
   "outputs": [],
   "source": [
    "# STUDENT CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "652df749-e305-4f6b-8627-9da9b7b2cd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_polygonize_landslides()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f207e7e-d4fd-4677-9545-6f7d781315c2",
   "metadata": {},
   "source": [
    "## Part 5: creating Python modules (4 pts)\n",
    "Now that we have all of these great functions that run our workflow, let's create some Python modules for them! One of our modules will be a script that we can run to generate a coseismic landslide inventory for any area of interest. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2993083f-6a48-4283-afa5-2be81a125a82",
   "metadata": {},
   "source": [
    "#### *Create a `utils.py` module*\n",
    "This module should contain all of the functions defined in the third code cell of this notebook. Use the command line or the file browser to create the `utils.py` file, then copy and paste all of these functions into it. At the top of the file, make sure to import all of the packages these functions depend on. Then run `!cat utils.py` to preserve the output in this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eed6d001-e210-4c8f-bd8c-b9aee344a7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statements for packages our utils depend on\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from scipy.optimize import curve_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71100de4-9a18-4419-9be9-d11d009736f7",
   "metadata": {
    "tags": [
     "hide_content",
     "hide_output"
    ]
   },
   "outputs": [],
   "source": [
    "# STUDENT CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce0690a-e85a-4416-ad66-e4163cc3edb8",
   "metadata": {},
   "source": [
    "#### ***Try out your `utils.py` module***\n",
    "Import and run the `calculate_date_before()` function with our `earthquake_date` variable to make sure it works. Then run `!cat utils.py` to preserve the output in this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a66d017-0d1a-41e1-8d60-83b3753433a5",
   "metadata": {
    "tags": [
     "hide_content"
    ]
   },
   "outputs": [],
   "source": [
    "# STUDENT CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "25e9ac52-1160-4a3f-a600-7a2287fea28a",
   "metadata": {
    "tags": [
     "hide_content"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2018-09-04'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STUDENT CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525d6bfc-af70-4c12-8ca9-10f02b9fc9fa",
   "metadata": {},
   "source": [
    "#### *Create a `main()` function*\n",
    "This function will run when our script is excecuted. It should run our entire analysis all the way through, so it will need to call all of the functions we made in Part 4. Before each function (or related group of functions) is called, write a short `print()` statement that describes what our script is doing. For example: \"creating seasonal median NDVI time series.\" In addition, our main function should use `argparse` to add seven arguments to our script: \n",
    "\n",
    "- `minx`: Minimum longitude of the bbox\n",
    "- `miny`: Minumum latitude of the bbox\n",
    "- `maxx`: Maximum longitude of the bbox\n",
    "- `maxy`: Maximum latitude of the bbox\n",
    "- `earthquake_date`\n",
    "- `cloud_cover_seasonal`: maximum cloud cover for seasonal median NDVI\n",
    "- `cloud_cover_time_series`: maximum cloud cover for NDVI time series\n",
    "\n",
    "Each argument should have a help string so that the user can understand how to use it. After parsing the arguments, your `main()` function should create the `earthquake_date` variable and `bbox` tuple variable from these arguments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9e70a0b1-b362-4f2b-b6fa-58a6c217c637",
   "metadata": {
    "tags": [
     "hide_content"
    ]
   },
   "outputs": [],
   "source": [
    "# STUDENT CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e82bd9d-6fed-4b0f-9eab-632410c8dd4c",
   "metadata": {},
   "source": [
    "#### *Create a `landslide_inventory.py` module*\n",
    "This module should contain the following, in order:\n",
    "1) An appropriate shebang line at the top\n",
    "2) Import statements for all of the packages needed to run the functions that comprise our workflow\n",
    "3) Import statements for the functions in our `utils.py` module needed to run our workflow\n",
    "4) Definitions for all of the functions needed to run our workflow (written by you in Part 4)\n",
    "5) Our `main()` function\n",
    "6) Some code to run `main()` if our module is being run directly (hint: `if __name__ == \"__main__\":`)\n",
    "\n",
    "When you're finished creating this module, do `!cat landslide_inventory.py` to preserve its contents here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "80033f4d-3fc4-4d90-acee-1c5be9b9fa16",
   "metadata": {
    "tags": [
     "hide_content",
     "hide_output"
    ]
   },
   "outputs": [],
   "source": [
    "# STUDENT CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ab77ee-3f3a-4b88-9f42-b299b15e3ccb",
   "metadata": {},
   "source": [
    "#### *Use help to check your module's usage*\n",
    "First, run `!chmod +x landslide_inventory.py` to change the permissions of your script, making it executable. Then, run `!./landslide_inventory.py -h` to see what your new module's usage is. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d167e93e-fc28-40b7-94ea-c958a4025597",
   "metadata": {
    "tags": [
     "hide_content"
    ]
   },
   "outputs": [],
   "source": [
    "# STUDENT CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bf1021d1-5b57-4df7-ab1d-d7b25e05ce27",
   "metadata": {
    "tags": [
     "hide_content",
     "hide_output"
    ]
   },
   "outputs": [],
   "source": [
    "# STUDENT CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334b7cbb-381b-46f3-8c0b-62c85624de0a",
   "metadata": {},
   "source": [
    "## Part 6: Running scripts (2 pts)\n",
    "Ok, now we have a script that we can run for any earthquake after 2015 to detect coseismic landslides! Let's see how easy it is to run our script for another location. Expect that the following code cell will take about five minutes to run. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "64628fc0-e6cf-4d71-8a56-7a6c3bc65a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating seasonal median NDVI dataset\n",
      "/opt/conda/lib/python3.11/site-packages/rasterio/warp.py:387: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix will be returned.\n",
      "  dest = _reproject(\n",
      "preparing NDVI time series\n",
      "creating landslide mask\n",
      "segmenting landslides\n",
      "polygonizing landslides\n",
      "done!\n",
      "CPU times: user 3.97 s, sys: 742 ms, total: 4.71 s\n",
      "Wall time: 4min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 2021 Haiti earthquake https://en.wikipedia.org/wiki/2021_Haiti_earthquake\n",
    "earthquake_date = '2021-08-14'\n",
    "minx = -74.03\n",
    "miny = 18.35\n",
    "maxx = -73.98\n",
    "maxy = 18.39\n",
    "cloud_cover_seasonal = 5\n",
    "cloud_cover_time_series = 50\n",
    "\n",
    "!./landslide_inventory.py $minx $miny $maxx $maxy $earthquake_date $cloud_cover_seasonal $cloud_cover_time_series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfda517-10bf-48a3-9993-37f3d2b4ebf0",
   "metadata": {},
   "source": [
    "#### *Explore your new landslide inventory*\n",
    "Uncomment the following code and explore the Haiti landslide inventory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cf150e55-80aa-4dcb-80a6-9561002cf625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # recomment when done exploring\n",
    "# landslide_gdf = gpd.read_file(f'landslides_{earthquake_date}_{minx}_{miny}_{maxx}_{maxy}.geojson')\n",
    "# landslide_gdf.explore(tiles=xyz.Esri.WorldImagery)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7412770d-b898-4cc0-a26a-6ba686c20c30",
   "metadata": {},
   "source": [
    "#### *Written Response: For the earthquakes in Japan and Haiti, compare and contrast:*\n",
    "1) The efficacy of our approach for generating a landslide inventory\n",
    "2) The spatial distribution and appearance of landslides that occurred\n",
    "\n",
    "How might you improve our approach? Consider ways you could make it more customizable, adaptive, user-friendly, organized, accurate, etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed02d30-eb01-4243-8fa1-48ce1fa2f901",
   "metadata": {},
   "source": [
    "**STUDENT WRITTEN RESPONSE HERE**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9b88ce-0572-4cdf-ad55-47eb0415ff57",
   "metadata": {},
   "source": [
    "#### *Written Response: If you were going to make a Python package from our two modules and host it on Github so others could use it, what would be some additional components/features it would require?*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44850676-c537-4be7-9a77-ca3ad5ec6260",
   "metadata": {},
   "source": [
    "**STUDENT WRITTEN RESPONSE HERE**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb2c4a2-09ee-4c44-a863-811c95a10a34",
   "metadata": {},
   "source": [
    "## Submit your work\n",
    "\n",
    "Make sure to do this process for both notebooks! Also push your Python modules, but **do not** push your data. \n",
    "\n",
    "1. Save this notebook with all code and output (Make sure when you save the notebook, all cells show their outputs).\n",
    "2. Use the terminal to stage, commit, and push your notebook to your GitHub repository. It should look something like this...\n",
    "- git add 01_lab.ipynb\n",
    "- git commit -m \"Completed Lab 01 exercises\"\n",
    "- git push\n",
    "3. Verify that your notebook appears in your GitHub repository. Double check to make sure all the ouputs are visible!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
